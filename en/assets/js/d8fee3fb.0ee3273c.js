"use strict";(self.webpackChunkrag_chat_bot_docs=self.webpackChunkrag_chat_bot_docs||[]).push([[1764],{854:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>B,contentTitle:()=>_,default:()=>D,frontMatter:()=>I,metadata:()=>A,toc:()=>y});var s=i(4848),t=i(8453);i(6540);const r="modelShowcase_LS5W",a="categorySection_lclY",l="categoryHeader_XK08",o="categoryLogo_NsWN",c="categoryDescription_gqlA",d="modelGrid_r772",u="modelCard_gEkP",m="modelHeader_zElW",h="modelName_Na3h",p="modelDate__bzL",g="modelDescription_CS3m",b="modelBody_LmOT",f="sectionTitle_S2Kb",k="benchmarkList_s2I6",v="benchmarkItem_Ma8n",x="relevanceSection_mMnK",M="pricingSection_fEZO",z="priceItem_TrEo",w="priceLabel_boAI",S="priceValue_Urw2",T=e=>{let{model:n}=e;return(0,s.jsxs)("div",{className:u,children:[(0,s.jsxs)("div",{className:m,children:[(0,s.jsx)("h3",{className:h,children:n.name}),n.date&&(0,s.jsx)("div",{className:p,children:n.date}),n.description.map(((e,n)=>(0,s.jsx)("p",{className:g,children:e},n)))]}),(0,s.jsxs)("div",{className:b,children:[(0,s.jsxs)("div",{className:x,children:[(0,s.jsx)("h4",{className:f,children:"Kanzlei-Relevanz:"}),(0,s.jsx)("p",{children:n.relevance})]}),(0,s.jsxs)("div",{children:[(0,s.jsx)("h4",{className:f,children:"Benchmarks:"}),(0,s.jsx)("ul",{className:k,children:n.benchmarks.map(((e,n)=>(0,s.jsx)("li",{className:v,children:e.description},n)))})]}),(0,s.jsxs)("div",{className:M,children:[(0,s.jsx)("h4",{className:f,children:"Kosten:"}),n.prices.map(((e,n)=>(0,s.jsxs)("div",{className:z,children:[(0,s.jsx)("span",{className:w,children:e.label}),(0,s.jsx)("span",{className:S,children:e.value})]},n)))]})]})]})},j=e=>{let{category:n}=e;return(0,s.jsxs)("div",{className:a,children:[(0,s.jsxs)("div",{className:l,children:[(0,s.jsx)("img",{src:n.logo,alt:`${n.description} logo`,className:o}),(0,s.jsx)("p",{className:c,children:n.description})]}),(0,s.jsx)("div",{className:d,children:n.models.map(((e,n)=>(0,s.jsx)(T,{model:e},n)))})]})},N=()=>{const e=[{logo:"/swmp-docs/img/logos/openai-logo.svg",description:"Optimiert f\xfcr Dokumentenverarbeitung, Datenbankinteraktionen (Deubner und Kanzlei Wissensarchiv) und Nutzerkommunikation.",models:[{name:"GPT-4.1",date:"Ver\xf6ffentlicht am 14. April 2025",description:["1 Million Token Kontextfenster","Wissensstand bis Juni 2024","Herausragende Verbesserungen bei Coding und Anweisungsbefolgung"],benchmarks:[{description:"54,6% auf SWE-bench Verified (21,4% besser als GPT-4o)"},{description:"38,3% auf MultiChallenge (10,5% besser als GPT-4o)"},{description:"72,0% auf Video-MME (f\xfcr Multimodal-Verst\xe4ndnis)"}],relevance:"GPT-4.1 eignet sich hervorragend f\xfcr komplexe Analysen und die Bearbeitung umfangreicher Dokumente. Der erweiterte Kontextumfang erm\xf6glicht es, ganze Vertragswerke zu erfassen und Inkonsistenzen zwischen verschiedenen Klauseln aufzudecken \u2013 eine kritische F\xe4higkeit f\xfcr die Praxis.",prices:[{label:"Input-Token:",value:"$2,00 pro Million"},{label:"Output-Token:",value:"$8,00 pro Million"}]},{name:"GPT-4.1 Mini",date:"Ver\xf6ffentlicht parallel zum Hauptmodell am 14. April 2025",description:["1 Million Token Kontextfenster","Wissensstand bis Juni 2024","Optimiert f\xfcr Balance zwischen Leistung und Geschwindigkeit"],benchmarks:[{description:"\xdcbertrifft in vielen Tests GPT-4o bei geringeren Kosten"},{description:"83% g\xfcnstiger als GPT-4o bei etwa halber Latenz"}],relevance:"Ein ausgezeichnetes Modell f\xfcr den t\xe4glichen Einsatz in Kanzleien, da es schnelle Antworten bei Standardanfragen liefert und gleichzeitig umfangreiche Dokumente verarbeiten kann.",prices:[{label:"Input-Token:",value:"$0,40 pro Million"},{label:"Output-Token:",value:"$1,60 pro Million"}]},{name:"GPT-4.1 Nano",date:"Schnellstes und kosteng\xfcnstigstes Modell der 4.1-Familie",description:["1 Million Token Kontextfenster trotz kompakter Gr\xf6\xdfe","Besonders schnell und kosteng\xfcnstig"],benchmarks:[{description:"MMLU-Score: 80,1%"},{description:"GPQA-Score: 50,3%"},{description:"Aider Polyglot Coding: 9,8%"}],relevance:"Ideal f\xfcr schnelle Klassifikationsaufgaben und das automatische Vervollst\xe4ndigen standardisierter Rechtsdokumente.",prices:[{label:"Input-Token:",value:"$0,10 pro Million"},{label:"Output-Token:",value:"$0,40 pro Million"}]},{name:"O4-Mini",date:"OpenAIs neuestes kleines Reasoning-Modell der o-Serie",description:["200.000 Token Kontextfenster","Analysiert die Anfrage in mehreren Schritten"],benchmarks:[{description:"Vergleichbare Leistung zu o3 bei etwa 10-fach geringeren Kosten"},{description:"Humanity's Last Exam: 14.28% Low & 17.7% High"}],relevance:"Bietet eine gute Balance zwischen Geschwindigkeit und Genauigkeit f\xfcr komplexe Analysen. Die hohe Genauigkeit macht es besonders wertvoll f\xfcr Anwendungen wie Semantic Search in Rechtsdatenbanken, Textklassifikation von Schrifts\xe4tzen und Dokumentenanalyse.",prices:[{label:"Input-Token:",value:"$1,10 pro Million"},{label:"Output-Token:",value:"$4,40 pro Million"}]},{name:"text-embedding-3-small",date:"Nachfolger von text-embedding-ada-002",description:["1536 Standard-Dimensionen","Optimiert f\xfcr Effizienz, niedrige Kosten und verbesserte Genauigkeit"],benchmarks:[{description:"MIRACL (Multilingual Retrieval): 44,0% (ada-002: 31,4%)"},{description:"MTEB (Massive Text Embedding Benchmark): 62,3% (ada-002: 61,0%)"},{description:"Bei reduzierter Dimension (512): MTEB-Score 61,6%"}],relevance:"Ideal f\xfcr Anwendungen wie Semantic Search in Rechtsdatenbanken, Textklassifikation von Schrifts\xe4tzen und Dokumentenanalyse. Die verbesserten multilingualen F\xe4higkeiten machen es besonders wertvoll f\xfcr deutsche Sprache.",prices:[{label:"Input:",value:"$0,02 pro Million"}]}]},{logo:"/swmp-docs/img/logos/perplexity-logo.svg",description:"Spezialisiert auf Internetrecherche, Informationssuche und Synthese aktueller Daten.",models:[{name:"Sonar",date:"",description:["Hauseigenes KI-Suchmodell von Perplexity AI","Basiert auf Llama 3.3 70B","Ultraschnelle Antwortgeschwindigkeit (1.200 Token pro Sekunde)"],benchmarks:[{description:"\xdcbertrifft in internen Tests Modelle wie GPT-4o mini und Claude 3.5 Haiku deutlich in der Nutzerzufriedenheit"},{description:"Erreichte hohe Platzierungen in der Search Arena Evaluation"}],relevance:"Besonders wertvoll f\xfcr juristische Recherchen, da es aktuelle Informationen aus dem Internet in Echtzeit abrufen und verarbeiten kann. Die hohe Geschwindigkeit macht es ideal f\xfcr den Einsatz bei Beratungsgespr\xe4chen, wo schnelle Antworten auf juristische Fragen ben\xf6tigt werden.",prices:[{label:"Input:",value:"1$ pro Million"},{label:"Output:",value:"1$ pro Million"}]},{name:"Sonar-Reasoning",date:"",description:["Erweiterte Version des Sonar-Modells mit verst\xe4rkten Reasoning-F\xe4higkeiten","Optimiert f\xfcr komplexe analytische Aufgaben","Focus Academic-Modus f\xfcr wissenschaftliche Quellen"],benchmarks:[{description:"Sonar-Reasoning-Pro erreichte einen Arena Score von 1136, statistisch gleichauf mit Gemini-2.5-Pro-Grounding (1142)"},{description:"In direkten Vergleichen besiegte Sonar-Reasoning-Pro-High Gemini-2.5-Pro-Grounding in 53% der F\xe4lle"}],relevance:"Die verbesserten Reasoning-F\xe4higkeiten machen dieses Modell besonders wertvoll f\xfcr komplexe juristische Analysen und das Erarbeiten von Rechtsgutachten. Der Focus Academic-Modus erm\xf6glicht gezielte Recherchen in wissenschaftlichen Quellen, was f\xfcr fundierte rechtliche Argumentationen wichtig ist.",prices:[{label:"Input:",value:"1$ pro Million"},{label:"Output:",value:"5$ pro Million"},{label:"Zus\xe4tzliche Kosten:",value:"$5 pro 1000 Suchen"}]},{name:"Sonar-Deep-Research",date:"",description:["Spezialisiertes Modell f\xfcr mehrstufige Informationssuche und komplexe Themen","F\xfchrt autonom Dutzende von Suchen durch und analysiert Hunderte von Quellen","Erstellt umfassende, quellenbasierte Berichte"],benchmarks:[{description:"Hohe Bewertungen bei komplexen Rechercheaufgaben"},{description:"21.1% Score in Humanity's Last Exam"}],relevance:"Ideal f\xfcr tiefgehende juristische Recherchen, Fallanalysen und die Erstellung fundierter Rechtsgutachten. Die F\xe4higkeit, autonom komplexe Rechercheaufgaben durchzuf\xfchren und Informationen aus verschiedenen Quellen zu synthetisieren, macht es zu einem wertvollen Werkzeug f\xfcr Anw\xe4lte bei der Bearbeitung komplizierter Rechtsf\xe4lle.",prices:[{label:"Input-Token:",value:"$2 pro Million"},{label:"Output-Token:",value:"$8 pro Million"},{label:"Reasoning:",value:"$3 pro Million"},{label:"Zus\xe4tzliche Kosten:",value:"$5 pro 1000 Suchen"}]}]}];return(0,s.jsx)("section",{className:r,children:(0,s.jsx)("div",{className:"container",children:e.map(((e,n)=>(0,s.jsx)(j,{category:e},n)))})})},I={id:"models",title:"KI Modelle",sidebar_position:5},_=void 0,A={id:"Benutzer/models",title:"KI Modelle",description:"",source:"@site/docs/Benutzer/Models.md",sourceDirName:"Benutzer",slug:"/Benutzer/models",permalink:"/swmp-docs/en/docs/Benutzer/models",draft:!1,unlisted:!1,editUrl:"https://github.com/swmp-partgmbb/swmp-docs/blob/main/docs/Benutzer/Models.md",tags:[],version:"current",sidebarPosition:5,frontMatter:{id:"models",title:"KI Modelle",sidebar_position:5},sidebar:"tutorialSidebar",previous:{title:"Quellen",permalink:"/swmp-docs/en/docs/Benutzer/sources"},next:{title:"Prompting",permalink:"/swmp-docs/en/docs/Benutzer/prompting"}},B={},y=[];function R(e){return(0,s.jsx)(N,{})}function D(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(R,{...e})}):R()}},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>l});var s=i(6540);const t={},r=s.createContext(t);function a(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);