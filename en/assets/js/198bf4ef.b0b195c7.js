"use strict";(self.webpackChunkrag_chat_bot_docs=self.webpackChunkrag_chat_bot_docs||[]).push([[6192],{3285:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>o,frontMatter:()=>t,metadata:()=>l,toc:()=>c});var i=s(4848),r=s(8453);const t={id:"large-language-models",title:"Large Language Models",sidebar_position:4},a="Large Language Models",l={id:"Research/RAG Best Practices/large-language-models",title:"Large Language Models",description:"Die Wahl eines hochwertigeren Sprachmodells (LLM) f\xfcr ein Retrieval-Augmented Generation (RAG) System hat mehrere wesentliche Auswirkungen:",source:"@site/docs/Research/RAG Best Practices/Large Language Models.md",sourceDirName:"Research/RAG Best Practices",slug:"/Research/RAG Best Practices/large-language-models",permalink:"/swmp-docs/en/docs/Research/RAG Best Practices/large-language-models",draft:!1,unlisted:!1,editUrl:"https://github.com/swmp-partgmbb/swmp-docs/blob/main/docs/Research/RAG Best Practices/Large Language Models.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{id:"large-language-models",title:"Large Language Models",sidebar_position:4},sidebar:"tutorialSidebar",previous:{title:"Query Preprocessing",permalink:"/swmp-docs/en/docs/Research/RAG Best Practices/query-preprocessing"},next:{title:"Azure Deployment",permalink:"/swmp-docs/en/docs/Research/Azure Deployment/"}},d={},c=[{value:"Evaluation",id:"evaluation",level:2}];function h(e){const n={annotation:"annotation",em:"em",h1:"h1",h2:"h2",header:"header",li:"li",math:"math",mn:"mn",mo:"mo",mrow:"mrow",p:"p",semantics:"semantics",span:"span",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"large-language-models",children:"Large Language Models"})}),"\n",(0,i.jsx)(n.p,{children:"Die Wahl eines hochwertigeren Sprachmodells (LLM) f\xfcr ein Retrieval-Augmented Generation (RAG) System hat mehrere wesentliche Auswirkungen:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Genauigkeit"})," und ",(0,i.jsx)(n.strong,{children:"Relevanz"})," der Antworten: Ein leistungsf\xe4higeres Sprachmodell kann pr\xe4zisere und relevantere Antworten generieren, indem es die aus dem Retrieval-Modul gewonnenen Informationen besser versteht und integriert."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Verst\xe4ndnis komplexer Anfragen"}),": Hochwertigere Modelle haben in der Regel ein besseres Verst\xe4ndnis komplexer Anfragen und k\xf6nnen subtilere Nuancen erfassen, was zu einer pr\xe4ziseren Generierung f\xfchrt."]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"evaluation",children:"Evaluation"}),"\n",(0,i.jsx)(n.p,{children:"F\xfcr den Einsatz eines Sprachmodells in einem Retrieval-Augmented-Generation (RAG) System f\xfcr internes Wissensmanagement k\xf6nnen die folgenden Benchmarks relevant sein:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"MMLU (Massive Multitask Language Understanding)"}),": Dieser Benchmark ist relevant, weil er das Sprachmodell in verschiedenen Wissensgebieten und Aufgaben testet, darunter auch rechtliche Fragestellungen. Er pr\xfcft die F\xe4higkeit des Modells, dom\xe4nenspezifisches Wissen zu verstehen und anzuwenden."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"GPQA (General-Purpose Question Answering)"}),": Da ein RAG-System h\xe4ufig darauf abzielt, genaue und pr\xe4zise Antworten auf Fragen zu liefern, ist dieser Benchmark von Bedeutung. GPQA testet die F\xe4higkeit des Modells, Antworten auf eine breite Palette von Fragen zu generieren, was direkt auf die Anforderungen eines internen Wissensmanagementsystems \xfcbertragbar ist."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Zwischen kommerziellen Modellen (Tab. 1) bietet GPT-4o hohe Leistung mit guter Datenschutzoption, w\xe4hrend Claude 3.5 etwas g\xfcnstiger ist, aber in Sachen Datenschutz fraglich bleibt. Gemini 1.5 ist kosteng\xfcnstiger, bietet aber weniger Leistung und Datenschutz."}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Model"}),(0,i.jsx)(n.th,{children:"MMLU"}),(0,i.jsx)(n.th,{children:"GPQA"}),(0,i.jsx)(n.th,{children:"Price (1M Input, 1M Output)"}),(0,i.jsx)(n.th,{children:"Enterprise Privacy"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"GPT-4o / GPT-4o-mini"}),(0,i.jsx)(n.td,{children:"88.7 / 82.0"}),(0,i.jsx)(n.td,{children:"53.6 / 40.2"}),(0,i.jsxs)(n.td,{children:[(0,i.jsxs)(n.span,{className:"katex",children:[(0,i.jsx)(n.span,{className:"katex-mathml",children:(0,i.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(n.semantics,{children:[(0,i.jsxs)(n.mrow,{children:[(0,i.jsx)(n.mn,{children:"5.00"}),(0,i.jsx)(n.mo,{separator:"true",children:","})]}),(0,i.jsx)(n.annotation,{encoding:"application/x-tex",children:"5.00, "})]})})}),(0,i.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(n.span,{className:"base",children:[(0,i.jsx)(n.span,{className:"strut",style:{height:"0.8389em",verticalAlign:"-0.1944em"}}),(0,i.jsx)(n.span,{className:"mord",children:"5.00"}),(0,i.jsx)(n.span,{className:"mpunct",children:","})]})})]}),"15.00 / ",(0,i.jsxs)(n.span,{className:"katex",children:[(0,i.jsx)(n.span,{className:"katex-mathml",children:(0,i.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(n.semantics,{children:[(0,i.jsxs)(n.mrow,{children:[(0,i.jsx)(n.mn,{children:"0.15"}),(0,i.jsx)(n.mo,{separator:"true",children:","})]}),(0,i.jsx)(n.annotation,{encoding:"application/x-tex",children:"0.15, "})]})})}),(0,i.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(n.span,{className:"base",children:[(0,i.jsx)(n.span,{className:"strut",style:{height:"0.8389em",verticalAlign:"-0.1944em"}}),(0,i.jsx)(n.span,{className:"mord",children:"0.15"}),(0,i.jsx)(n.span,{className:"mpunct",children:","})]})})]}),"0.60"]}),(0,i.jsx)(n.td,{children:"Ja"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Claude 3.5 Sonnet / Claude 3 Haiku"}),(0,i.jsx)(n.td,{children:"88.7 / 75.2"}),(0,i.jsx)(n.td,{children:"59.4 / 33.3"}),(0,i.jsxs)(n.td,{children:[(0,i.jsxs)(n.span,{className:"katex",children:[(0,i.jsx)(n.span,{className:"katex-mathml",children:(0,i.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(n.semantics,{children:[(0,i.jsxs)(n.mrow,{children:[(0,i.jsx)(n.mn,{children:"3.00"}),(0,i.jsx)(n.mo,{separator:"true",children:","})]}),(0,i.jsx)(n.annotation,{encoding:"application/x-tex",children:"3.00, "})]})})}),(0,i.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(n.span,{className:"base",children:[(0,i.jsx)(n.span,{className:"strut",style:{height:"0.8389em",verticalAlign:"-0.1944em"}}),(0,i.jsx)(n.span,{className:"mord",children:"3.00"}),(0,i.jsx)(n.span,{className:"mpunct",children:","})]})})]}),"15.00 / ",(0,i.jsxs)(n.span,{className:"katex",children:[(0,i.jsx)(n.span,{className:"katex-mathml",children:(0,i.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(n.semantics,{children:[(0,i.jsxs)(n.mrow,{children:[(0,i.jsx)(n.mn,{children:"0.25"}),(0,i.jsx)(n.mo,{separator:"true",children:","})]}),(0,i.jsx)(n.annotation,{encoding:"application/x-tex",children:"0.25, "})]})})}),(0,i.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(n.span,{className:"base",children:[(0,i.jsx)(n.span,{className:"strut",style:{height:"0.8389em",verticalAlign:"-0.1944em"}}),(0,i.jsx)(n.span,{className:"mord",children:"0.25"}),(0,i.jsx)(n.span,{className:"mpunct",children:","})]})})]}),"1.25"]}),(0,i.jsx)(n.td,{children:"Fraglich"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Gemini 1.5 PRO / Gemini 1.5 Flash"}),(0,i.jsx)(n.td,{children:"85.9 / 78.9"}),(0,i.jsx)(n.td,{children:"46.2 / 39.5"}),(0,i.jsxs)(n.td,{children:[(0,i.jsxs)(n.span,{className:"katex",children:[(0,i.jsx)(n.span,{className:"katex-mathml",children:(0,i.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(n.semantics,{children:[(0,i.jsxs)(n.mrow,{children:[(0,i.jsx)(n.mn,{children:"3.50"}),(0,i.jsx)(n.mo,{separator:"true",children:","})]}),(0,i.jsx)(n.annotation,{encoding:"application/x-tex",children:"3.50, "})]})})}),(0,i.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(n.span,{className:"base",children:[(0,i.jsx)(n.span,{className:"strut",style:{height:"0.8389em",verticalAlign:"-0.1944em"}}),(0,i.jsx)(n.span,{className:"mord",children:"3.50"}),(0,i.jsx)(n.span,{className:"mpunct",children:","})]})})]}),"10.50 / ",(0,i.jsxs)(n.span,{className:"katex",children:[(0,i.jsx)(n.span,{className:"katex-mathml",children:(0,i.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,i.jsxs)(n.semantics,{children:[(0,i.jsxs)(n.mrow,{children:[(0,i.jsx)(n.mn,{children:"0.075"}),(0,i.jsx)(n.mo,{separator:"true",children:","})]}),(0,i.jsx)(n.annotation,{encoding:"application/x-tex",children:"0.075, "})]})})}),(0,i.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,i.jsxs)(n.span,{className:"base",children:[(0,i.jsx)(n.span,{className:"strut",style:{height:"0.8389em",verticalAlign:"-0.1944em"}}),(0,i.jsx)(n.span,{className:"mord",children:"0.075"}),(0,i.jsx)(n.span,{className:"mpunct",children:","})]})})]}),"0.30"]}),(0,i.jsx)(n.td,{children:"Eher nein"})]})]})]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.em,{children:"Table 1: Closed-Source Modelle"})}),"\n",(0,i.jsx)(n.p,{children:"Bei der Verwendung von Sprachmodellen zur Verarbeitung personenbezogener Daten k\xf6nnen Open-Source Modelle (Tab. 2) gew\xe4hlt werden."}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Model"}),(0,i.jsx)(n.th,{children:"MMLU"}),(0,i.jsx)(n.th,{children:"GPQA"}),(0,i.jsx)(n.th,{children:"Requirements VRAM (FP16)"}),(0,i.jsx)(n.th,{children:"License"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Llama 3.1 8B / 70B / 405B"}),(0,i.jsx)(n.td,{children:"73.0 / 86.0 / 88.6"}),(0,i.jsx)(n.td,{children:"32.8 / 46.7 / 51.1"}),(0,i.jsx)(n.td,{children:"16 GB  / 140 GB / 810 GB"}),(0,i.jsx)(n.td,{children:"Community License"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Mistral 7B / Large 2"}),(0,i.jsx)(n.td,{children:"60.1 / 84.0"}),(0,i.jsx)(n.td,{children:"---"}),(0,i.jsx)(n.td,{children:"14 GB  / 246 GB"}),(0,i.jsx)(n.td,{children:"Mistral Research License / Apache 2.0"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Mixtral 7B / 8x7B / 8x22B"}),(0,i.jsx)(n.td,{children:"63.0 / 71.0 / 84.0"}),(0,i.jsx)(n.td,{children:"---"}),(0,i.jsx)(n.td,{children:"14 GB  / 112 GB / 252 GB"}),(0,i.jsx)(n.td,{children:"Apache 2.0"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Qwen2-72B"}),(0,i.jsx)(n.td,{children:"84.2"}),(0,i.jsx)(n.td,{children:"37.9"}),(0,i.jsx)(n.td,{children:"148 GB"}),(0,i.jsx)(n.td,{children:"Qianwen License"})]})]})]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.em,{children:"Table 2: Open-Source Modelle"})}),"\n",(0,i.jsx)(n.p,{children:"Open-Source-Modelle bieten eine gr\xf6\xdfere Flexibilit\xe4t bei der Lizenzierung und Leistung."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Llama 3.1"})," Modelle zeichnen sich durch eine Community-Lizenz aus, die sie besonders f\xfcr interne und gemeinschaftsbasierte Projekte attraktiv macht, jedoch weniger f\xfcr den kommerziellen Einsatz geeignet ist. Gleichzeitig bietet Llama 3.1 eine gute Balance zwischen Leistung und VRAM-Anforderungen, was sie zu einer soliden Wahl macht."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Mistral"})," Modelle bieten eine Kombination aus einer Forschungs- und einer Apache-Lizenz, was je nach Modell unterschiedliche Nutzungsm\xf6glichkeiten bietet. Obwohl die Leistung von Mistral gemischt ist, bleibt es vielseitig einsetzbar."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Mixtral"})," Modelle, die unter der ",(0,i.jsx)(n.strong,{children:"Apache 2.0-Lizenz"})," stehen, sind besonders attraktiv f\xfcr kommerzielle Projekte, da diese Lizenz eine sehr offene und flexible Nutzung erm\xf6glicht. In Bezug auf die Leistung zeigt Mixtral ebenfalls eine gewisse Vielseitigkeit."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Qwen2-72B"})," Modell hingegen bietet eine gute Leistung, ben\xf6tigt aber viel VRAM. Aufgrund der spezifischen Qianwen-Lizenz sollte Qwen2-72B sorgf\xe4ltig gepr\xfcft werden, um sicherzustellen, dass es den Anforderungen des Projekts entspricht."]}),"\n"]})]})}function o(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>l});var i=s(6540);const r={},t=i.createContext(r);function a(e){const n=i.useContext(t);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);